\documentclass{article}
\usepackage{geometry}
\geometry{
	a4paper,
	total={170mm,257mm},
	left=20mm,
	top=20mm,
}
\usepackage{amsmath}
\usepackage{centernot}
\usepackage{soul}
\usepackage{float}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{bbm}
\usepackage{tikz}
\usepackage{subcaption}
\graphicspath{ {./images/} }
\usepackage[utf8]{inputenc}
\usepackage{array, makecell}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\newcolumntype{M}[1]{>{\centering\arraybackslash}m{#1}}
\usepackage{epigraph}
\title{Machine Learning Project Proposal}
\date{Jun 9th 2019}
\author{Xicheng XIA}
\begin{document}
	\maketitle
\section{Project description}
We decided to choose \textit{House Prices: Advanced Regression Techniques} from the Kaggle competition as our project topic. Our aim is to use simple machine learning models such as \textit{Lasso Regression} to obtain a decent result after applying feature engineering technique.\\

\section{Data Description}
This competition requires us to predict the exact house price with 79 original features. Train set is $1459\times 79$ with given house prices for training, test set is $1459\times 79$ without knowing house prices.

\section{Methods of Research}
\begin{itemize}
	\item[a] Read those kernels;
	\item[b] Data cleansering. Cope with missing values and abnormal values(median filter, winsorize);
	\item[c] Single factor exploration;
	\item[d] Feature engineering. Dummies, linear/non-linear transformations;
	\item[e] Dimention reduction. PCA;
	\item[f] Scale the data. Normalization/Standarization, max\_min\_scaler.
	\item[g] Select models and parameters. Lasso/Ridge/SVR, cross-examination/regularization/penalization/learning-rate/iteration-times
\end{itemize}


\section{Our Goal}
The competition score is measured by the out-of-sample \textit{Root Mean Squared Logarithmic Error}, we expected to at least obatin a score less than 0.15 (ranked around 3000), an optimistic expectation is 0.13 (ranked around 2000).
\end{document}