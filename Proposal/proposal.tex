\documentclass{article}
\usepackage{geometry}
\geometry{
	a4paper,
	total={170mm,257mm},
	left=20mm,
	top=20mm,
}
\usepackage{amsmath}
\usepackage{centernot}
\usepackage{soul}
\usepackage{float}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{bbm}
\usepackage{tikz}
\usepackage{subcaption}
\graphicspath{ {./images/} }
\usepackage[utf8]{inputenc}
\usepackage{array, makecell}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\newcolumntype{M}[1]{>{\centering\arraybackslash}m{#1}}
\usepackage{epigraph}
\title{Machine Learning Project Proposal\_Group 9}
\date{Jun 11th 2019}
\author{Xia Xicheng, Shen Li, Li Feijiao, Wang Yifan, Jin Weiguo}
\begin{document}
	\maketitle
\section{Project Description}
We decided to choose \textit{House Prices: Advanced Regression Techniques} from the Kaggle competition as our project topic. Our goal is to use simple machine learning models such as \textit{Lasso Regression} to obtain a decent result after applying feature engineering technique.\\

\section{Data Structure}
We are given both training dataset ($1459\times 81$) and test dataset ($1459\times 80$). Training datasets includes 1459 entries with 81 variables, in which 80 are explanatory variables and 1 is explained house price. \

\noindent Test dataset is similar to training dataset except for the absence of house price.

\section{Methodology}
\begin{itemize}
	\item[a] Read those kernels;
	\item[b] Data cleansering. Cope with missing values and abnormal values(median filter, winsorize);
	\item[c] Single factor exploration (allows us to narrow our focus on plausibly important factors based on our intuition);
	\item[d] Feature engineering. Dummies, linear/non-linear transformations;
	\item[e] Dimension reduction. PCA;
	\item[f] Scale the data. Normalization/Standardization, max\_min\_scalar.
	\item[g] Select models and parameters. Lasso/Ridge/SVR, cross-examination/regularization/penalization/learning-rate/iteration-times
\end{itemize}


\section{Performance Evaluation Criteria}
Kaggle ranks all the submissions according to their relative performance. The competition score is measured by the out-of-sample \textit{Root Mean Squared Logarithmic Error}. Currently, there are 4652 submissions from all over the world. As beginners in the machine learning field, we would like to set our target reasonably at the ranking of 3000, with a score (error) of less than 0.15. An optimistic target would be 0.13 (ranked around 2000).
\end{document}